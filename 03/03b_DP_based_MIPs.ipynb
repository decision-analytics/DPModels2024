{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"img/bigsem.png\" width=\"40%\" align=\"right\">\n",
    "<img src=\"img/logo_wiwi.png\" width=\"20%\" align=\"left\">\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<br><br><br><br>\n",
    "\n",
    "# Dynamic Programming Models in Combinatorial Optimization\n",
    "**Winter Term 2022/23**\n",
    "\n",
    "\n",
    "# 3. DP Models within MIP Formulations\n",
    "<img src=\"img/decision_analytics_logo.png\" width=\"17%\" align=\"right\">\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "**J-Prof. Dr. Michael RÃ¶mer |  Decision Analytics Group**\n",
    "                                                    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numba import njit, typeof\n",
    "from typing import NamedTuple, Callable, Any\n",
    "from dataclasses import dataclass, field\n",
    "from numba.experimental import jitclass\n",
    "import networkx as nx\n",
    "from collections import deque\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Overview\n",
    "- DP Models / DDs as basis of flow-based MIPs\n",
    "  - example: Knapsack Problem\n",
    "- The Multiple Knapsack Problem\n",
    "  - standard MIP model\n",
    "  - as DP Model\n",
    "  - as DP model with multiple flow units\n",
    " - More generic DP  models (without stages)\n",
    " - Example: Shift Scheduling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example: the 0/1 knapsack problem\n",
    "\n",
    "Given \n",
    "- a knapsack with a capacity $W$ \n",
    "- and a set of items, each with a weight $w_i$ and a value $p_i$\n",
    "- determine the the subset of the items to put in the knapsack such that\n",
    "  - the total value of the items in the knapsack is maximal and\n",
    "  - the total weight of the items in the knapsack does not exceed $W$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Example:**\n",
    "\n",
    "<img src=\"./img/greedy/07.png\" width=\"20%\" align=\"right\">\n",
    "\n",
    "Assume you are a thief and you are about to steal the three items depicted below from an appartment. However, your backpack can only fit 35 lbs. Which items should you take?\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"./img/greedy/08.png\" width=\"40%\" align=\"left \">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DP(NamedTuple):\n",
    "    feasible_decisions : Callable\n",
    "    transition_function : Callable\n",
    "    cost_function : Callable\n",
    "    direction : str # 'max' or 'min'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Generic helper functions to deal with maximization and minimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "@njit \n",
    "def better(value1, value2, direction):\n",
    "    if direction == \"min\":\n",
    "        return value1 < value2\n",
    "    else:\n",
    "        return value1 > value2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "@njit\n",
    "def best_element_and_value(elements, values, direction):\n",
    "    if direction == \"min\":\n",
    "        best_index = np.argmin(values)\n",
    "    else:\n",
    "        best_index = np.argmax(values)\n",
    "    return elements[best_index], values[best_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "@njit\n",
    "def get_n_best_elements_and_values(n, elements, values, direction):\n",
    "    \n",
    "    if direction == \"min\":\n",
    "        sorted_indexes = np.argsort(values)\n",
    "    else:\n",
    "        sorted_indexes = np.argsort(-values)\n",
    "    return elements[sorted_indexes[:n]], values[sorted_indexes[:n]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 2]), array([2, 3]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_n_best_elements_and_values(2, np.array([1,2,3]), np.array([2,3,5]), 'min')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example: A DP model for the Knapsack Problem\n",
    "- given a  knapsack instance with $N$ items with weights $w_k$ and profits $p_k$ (zero-indexed) and capacity $W$ \n",
    "\n",
    "- state $x_k$: accumulated weight after adding the first $k-1$ items, $x_0 = 0$\n",
    "- decision $u_k \\in \\{0, 1\\}$ (0: do not add item $k$ to the knapsack; 1: add item $k$)\n",
    "- $U_k(x_k) = \\begin{cases} \n",
    "                \\{0,1\\} \\quad \\mathrm{if} \\quad x_k + w_k \\leq W \\\\\n",
    "                \\{0 \\} \\quad \\mathrm{else}\n",
    "\\end{cases}$\n",
    "\n",
    "- $f(x_k, u_k) = x_k + w_k u_k $\n",
    "\n",
    "- $g(x_k, u_k) = p_k u_k$\n",
    "\n",
    "We have a maximization-objective:\n",
    "\n",
    "$$\\max_{u_0,..,u_k,..u_{N-1}} \\sum_{k=0}^{N-1} g_k(x_k,u_k)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Knapsack DP Model in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "class  KPInstance(NamedTuple):\n",
    "    values:np.array\n",
    "    weights:np.array\n",
    "    capacity:int\n",
    "    N:int   \n",
    "\n",
    "@njit\n",
    "def feasible_decisions_kp(instance, k, acc_weight):    \n",
    "    if acc_weight + instance.weights[k] <= instance.capacity: return np.array([0,1])\n",
    "    else: return np.array([0])\n",
    "\n",
    "@njit\n",
    "def transition_function_kp(instance, k, acc_weight, put):\n",
    "    return acc_weight + put*instance.weights[k]\n",
    "\n",
    "@njit\n",
    "def cost_function_kp(instance, k, acc_weight, put):\n",
    "      return put*instance.values[k]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Putting all together, and stating that we have a maximization objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "dp_kp = DP(feasible_decisions_kp, transition_function_kp,  cost_function_kp, \"max\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## An instance reader function for the Knapsack Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_kp_instance(filename, sorted=True):\n",
    "    weights=[]\n",
    "    values=[]\n",
    "    with open(filename) as f: # open the file\n",
    "        line = f.readline().split()  # split first row\n",
    "        number_of_items = int(line[0]) # read number of items\n",
    "        capacity = int(line[1]) # read capacity\n",
    "        for i in range(number_of_items): # read rows for the items\n",
    "            line = f.readline().split() # split row\n",
    "            values.append(int(line[0])) # read value\n",
    "            weights.append(int(line[1])) # read weight\n",
    "            \n",
    "    values = np.array(values)\n",
    "    weights = np.array(weights)    \n",
    "    \n",
    "    \n",
    "    if sorted:\n",
    "        sorted_indexes = np.argsort(-1* values/weights)\n",
    "    values = values[sorted_indexes]\n",
    "    weights = weights[sorted_indexes]\n",
    "     \n",
    "        \n",
    "    return KPInstance(values, weights, capacity, number_of_items)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filename = \"./../problems/knapsack/instances/knapPI_1_5000_1000_1\"\n",
    "filename = \"./../problems/knapsack/instances/knapPI_1_100_1000_1\"\n",
    "kp_instance = read_kp_instance(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Exact Decision Diagrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "- given a DP model, we can view an exact DD as a state-transition-graph, with one exception:\n",
    "  - we introduce a terminal node that forms the target of all arcs emanating from layer $N-1$\n",
    "- just as in the DP by reaching algorithm, we can construct the exact DD by \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## A Decision Diagram data structure\n",
    "\n",
    "We will introduce a class `DecisionDiagram` that represents a DD\n",
    "- consisting of $N$ + 1 layers indexed from 0 to $N$\n",
    "    - each layer is a dictionary where the key is a state and the value is a `NodeInfo` object\n",
    "  - (problem-specific) state values representing the start (source) state and the sink state\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class DecisionDiagram:        \n",
    "    def __init__(self, number_of_layers, source_layer, source_state, sink_state, direction = 'max'):\n",
    "        self.g = nx.MultiDiGraph()\n",
    "        self.number_of_layers = number_of_layers\n",
    "        self.layers = [set() for l in range(0, number_of_layers)]\n",
    "        self.source_state = source_state\n",
    "        self.sink_state = sink_state\n",
    "        self.layers[source_layer].add(source_state)\n",
    "        self.g.add_node((source_layer, source_state), best_dist = 0, best_in_edge = None)\n",
    "        self.direction = direction\n",
    "        self.last_exact_layer = source_layer\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Building an exact DD by top-down-compilation\n",
    "- building an exact DD is basically the same as building the DP by reaching: states are \"discovered\" layer per layer\n",
    "- by applying the transition function to each feasible decision in each state in the layer under consideration\n",
    "- in the following algorithm, we store the best distance from the source / root node as well as the preceding node in each node\n",
    "- this means that the best path in the DD is computed \"in passing\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Building an exact DD by top-down-compilation in Python\n",
    "- observe: here, we introduce a sink state as a \"dummy\" state (that is otherwise not reachable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_exact_dd(dp, instance, start_layer, start_state, sink_state):\n",
    "    \n",
    "    dd = DecisionDiagram(instance.N+1, start_layer, start_state, sink_state, dp.direction)\n",
    "    \n",
    "    state = start_state\n",
    "    total_cost = 0\n",
    "    \n",
    "    for k in range(0,instance.N):\n",
    "        \n",
    "        for state in dd.layers[k]:\n",
    "            decisions = dp.feasible_decisions(instance, k, state)\n",
    "            \n",
    "            for decision in decisions:\n",
    "                if k < instance.N -1: # if we are the final layer, point to the \"sink state\"\n",
    "                    next_state = dp.transition_function(instance,k,state, decision)\n",
    "                else:\n",
    "                    next_state = sink_state\n",
    "                \n",
    "                add_transition_dd(dd, k, state, decision, next_state, dp.cost_function(instance, k, state, decision))\n",
    "   \n",
    "    k = instance.N-1\n",
    "    \n",
    "    return dd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Creating new nodes: adding the result of a transition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_transition_dd(dd, layer_index, state, decision, result_state, cost):\n",
    "    \n",
    "    layer = dd.layers[layer_index]\n",
    "    result_layer = dd.layers[layer_index+1] \n",
    "    \n",
    "    node = (layer_index, state)\n",
    "    \n",
    "    result_node = (layer_index+1, result_state)\n",
    " \n",
    "    result_dist = dd.g.nodes[node][\"best_dist\"] + cost  \n",
    "\n",
    "    if result_state not in result_layer:\n",
    "        result_layer.add(result_state)\n",
    "        dd.g.add_node(result_node, best_dist=result_dist, best_in_edge=(node,result_node,decision))\n",
    "        \n",
    "    elif better(result_dist, dd.g.nodes[result_node][\"best_dist\"], dd.direction): \n",
    "        dd.g.nodes[result_node][\"best_dist\"] = result_dist\n",
    "        dd.g.nodes[result_node][\"best_in_edge\"]=(node,result_node,decision)\n",
    "    \n",
    "    dd.g.add_edge(node, result_node, decision, cost=cost)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Trying it out, and some utility functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "dd = build_exact_dd(dp_kp, kp_instance, 0, 0,-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "..getting the best objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def get_best_objective (dd):\n",
    "    return dd.g.nodes[(dd.number_of_layers-1,dd.sink_state)][\"best_dist\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9147"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_best_objective (dd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "..getting the best path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_best_path(dd):\n",
    "    \n",
    "    decisions = []\n",
    "    \n",
    "    state =  dd.sink_state\n",
    "    k = dd.number_of_layers - 1\n",
    "        \n",
    "    while k > 0:\n",
    "       # print(k)\n",
    "        node,  next_node, decision = dd.g.nodes[(k,state)][\"best_in_edge\"]\n",
    "        #print (dd.layers[k+1])\n",
    "        decisions.append(decision)\n",
    "        k, state = node\n",
    "        \n",
    "        \n",
    "\n",
    "    return  dd.g.nodes[(dd.number_of_layers-1,dd.sink_state)][\"best_dist\"], list(reversed(decisions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_best_path(dd)[1][:20] ## first 10 nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "..getting the number of nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def get_number_of_nodes(dd):\n",
    "    return dd.g.number_of_nodes()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80725"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_number_of_nodes(dd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Reducing an exact DD\n",
    "\n",
    "One of the key ideas from DDs is that very often, a DD can be compressed / reduced by merging nodes \n",
    "that \n",
    "- do not have identical (top-down) states\n",
    "- but are nonetheless **equivalent** in the sense that they have the same *completions*, that is, the same set of partial solutions until the end (the solution sets of their tail subproblems are identical)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "This type of equivalence can be identified by an upward-pass starting from the bottom layer $N$ to layer $0$\n",
    "\n",
    "- in each layer $k$, two nodes are equivalent (are in the same equivalence class) if \n",
    "  - they have the same set of feasible decisions \n",
    "  - these decisions have the same costs\n",
    "  - the corresponding arcs point to the same set of nodes in the subsequent layer $k+1$\n",
    "- for each equivalence class, merge all nodes in that class into a single node\n",
    "\n",
    "**Attention:** The following implementation assumes that the decision costs are state-independent. If the decision costs (the arc costs) are state-dependent, then we need to add a check for identical costs, too"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Implementing the DD reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_exact_dd(dd):\n",
    "    \n",
    "    #proceed from the bottom (last layer) to the top\n",
    "    k = len(dd.layers)-1\n",
    "    while k > 0:\n",
    "        \n",
    "        # a dict with key: decisions and resulting nodes (forming an equivalence class)\n",
    "        #       and value: list of states falling into that class\n",
    "        eq_classes = {}\n",
    "    \n",
    "        #1. collect equivalence classes and states/nodes in each class\n",
    "        for state in dd.layers[k]:\n",
    "            \n",
    "            out_arc_info = []\n",
    "            \n",
    "            for u,v,decision,data in dd.g.out_edges((k,state),keys=True, data=True):\n",
    "                out_arc_info.append((decision,v,data[\"cost\"]))\n",
    "                \n",
    "            eq_class = tuple(sorted(out_arc_info))\n",
    "            \n",
    "            if eq_class not in eq_classes:\n",
    "                eq_classes[eq_class] = [state]                \n",
    "            else:\n",
    "                eq_classes[eq_class].append(state)\n",
    "        \n",
    "        # 2. merge all states in each class into a single node\n",
    "        for eq_class, states in eq_classes.items():            \n",
    "            while len(states) > 1:\n",
    "                state_remove = states.pop()\n",
    "                merge_nodes(dd, k, states[0], state_remove)\n",
    "                \n",
    "        k=k-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Merging two nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def merge_nodes(dd, layer_index, state_orig, state_remove):\n",
    "    \n",
    "    node_orig = (layer_index, state_orig)\n",
    "    node_remove = (layer_index, state_remove)\n",
    "    \n",
    "    layer = dd.layers[layer_index]\n",
    "\n",
    "    \n",
    "\n",
    "    # 1. Keep the best distance to from the source\n",
    "    if better(dd.g.nodes[node_remove][\"best_dist\"], dd.g.nodes[node_orig][\"best_dist\"], dd.direction):        \n",
    "        (u,v,d) = dd.g.nodes[node_remove][\"best_in_edge\"]\n",
    "        dd.g.nodes[node_orig][\"best_in_edge\"] = (u,node_orig,d)\n",
    "        dd.g.nodes[node_orig][\"best_dist\"] = dd.g.nodes[node_remove][\"best_dist\"]\n",
    "\n",
    "    \n",
    "    # update best stuff\n",
    "    \n",
    "    for u, v, decision,data in dd.g.out_edges(node_remove, keys=True, data=True):\n",
    "        if dd.g.nodes[v][\"best_in_edge\"] == (u,v,decision):\n",
    "            dd.g.nodes[v][\"best_in_edge\"] = (node_orig, decision, v)\n",
    "            \n",
    "\n",
    "    # 3. redirect the in-arcs from the removed node to the node to be kept\n",
    "    \n",
    "    arcs_to_add = []\n",
    "    for u,v,decision,data in dd.g.in_edges(node_remove, keys = True, data=True):\n",
    "        arcs_to_add.append((u,node_orig, decision, data))\n",
    "                           \n",
    "    dd.g.remove_node(node_remove)\n",
    "    layer.remove(state_remove)\n",
    "    \n",
    "    dd.g.add_edges_from(arcs_to_add)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Trying it  out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reduced nodes 19957\n"
     ]
    }
   ],
   "source": [
    "reduce_exact_dd(dd)\n",
    "\n",
    "print (\"reduced nodes\", get_number_of_nodes(dd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# DP Models within MIPs\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Observation:  DDs and optimal paths\n",
    "\n",
    "- instead of computing the optimal path \"on the fly\", we could simply compute the longest path in the DD from the source to the sink (terminal node)\n",
    "- since we have a directed acyclic graph, this can even be done in linear time\n",
    "- we can simply use the function `dag_longest_path_length` from NetworkX\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9147"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd = build_exact_dd(dp_kp, kp_instance, 0, 0,-1)\n",
    "\n",
    "nx.dag_longest_path_length(dd.g, weight=\"cost\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Optimal Paths using a MIP solver\n",
    "\n",
    "- as you may know, instead of calling a shortest path algorithm we may just formulate the shortest path problem as a **min-cost-flow problem** that can can, in turn, be solved by a MIP\n",
    "\n",
    "The mathematical model would look as follows (assuming that we have a circulation arc $e^\\mathrm{circ}$ from source to sink node):\n",
    "\n",
    "- let the graph be defined as $G(N,E)$\n",
    "- let us denote the flow variables with $x$ (we're back in the MIP world ;-))\n",
    "\n",
    "\n",
    "$$\\min \\sum_{e \\in E}c_e x_e$$\n",
    "\n",
    "s.t.\n",
    "$$\n",
    " \\sum_{e \\in v^-} x_e = \\sum_{e \\in v^+} x_e \\quad \\forall v \\in N \\\\\n",
    " x_e^\\mathrm{circ} = 1 \\\\\n",
    " x_e \\in \\{0, 1\\} \\quad \\forall e \\in E $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def build_network_flow_component(m, dd, flow_size = 1):    \n",
    "    \n",
    "    ## add flow vars    \n",
    "    edge_to_flow_var = {}  \n",
    "\n",
    "    for e, data in dd.g.edges.items():\n",
    "            edge_to_flow_var[e] = m.addVar(vtype=GRB.INTEGER, obj = data[\"cost\"] )\n",
    "    \n",
    "    ## if not existing yet, add circulation arc\n",
    "    if dd.g.out_degree ( (dd.number_of_layers-1, dd.sink_state) ) == 0:  \n",
    "        dd.g.add_edge( (dd.number_of_layers-1, dd.sink_state),  (0, dd.source_state), key=-1, cost=0)      \n",
    "\n",
    "    ## add flow var for circulation arc and fix flow\n",
    "    edge_to_flow_var[((dd.number_of_layers-1, dd.sink_state),  (0, dd.source_state), -1)] = m.addVar(vtype=GRB.INTEGER, lb=flow_size, ub=flow_size)\n",
    "    \n",
    "    ## add flow balance constraints\n",
    "            \n",
    "    for v in dd.g.nodes():\n",
    "        m.addConstr(gp.quicksum(edge_to_flow_var[e] for e in dd.g.in_edges(v,keys=True)) == gp.quicksum(edge_to_flow_var[e] for e in dd.g.out_edges(v, keys=True) ))\n",
    "\n",
    "    return edge_to_flow_var\n",
    "            \n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Optimal Paths using a MIP solver: Trying it Out\n",
    "\n",
    "Read instance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "filename = \"./../problems/knapsack/instances/knapPI_1_100_1000_1\"\n",
    "kp_instance = read_kp_instance(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Build DD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80725"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd = build_exact_dd(dp_kp, kp_instance, 0, 0,-1)\n",
    "get_number_of_nodes(dd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Build MIP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "m = gp.Model(\"knapsack_dd\")\n",
    "m.ModelSense = GRB.MAXIMIZE\n",
    "edge_to_flow_var = build_network_flow_component(m, dd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Solve it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gurobi Optimizer version 12.0.0 build v12.0.0rc1 (win64 - Windows 10.0 (19045.2))\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i7-10750H CPU @ 2.60GHz, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 6 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Optimize a model with 19957 rows, 36234 columns and 72468 nonzeros\n",
      "Model fingerprint: 0xc8bdd3e0\n",
      "Variable types: 0 continuous, 36234 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [7e+00, 1e+03]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [0e+00, 0e+00]\n",
      "Presolve removed 19957 rows and 36234 columns\n",
      "Presolve time: 0.21s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.23 seconds (0.27 work units)\n",
      "Thread count was 1 (of 12 available processors)\n",
      "\n",
      "Solution count 1: 9147 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 9.147000000000e+03, best bound 9.147000000000e+03, gap 0.0000%\n",
      "CPU times: total: 234 ms\n",
      "Wall time: 256 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "m.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9147.0\n"
     ]
    }
   ],
   "source": [
    "print(m.ObjVal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Extracting the solution\n",
    "\n",
    "- to get the solution path, we can just \"follow\" the flow variables with value 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.int64(1),\n",
       " np.int64(1),\n",
       " np.int64(1),\n",
       " np.int64(1),\n",
       " np.int64(1),\n",
       " np.int64(1),\n",
       " np.int64(1),\n",
       " np.int64(1),\n",
       " np.int64(1),\n",
       " np.int64(1)]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_solution_path(edge_to_flow_var, dd):\n",
    "    \n",
    "    decisions = []\n",
    "    \n",
    "    \n",
    "    node = (0, dd.source_state)    \n",
    "    while node[1] != dd.sink_state:\n",
    "        for node, target_node, decision in dd.g.out_edges(node, keys=True):\n",
    "            if edge_to_flow_var[node, target_node, decision].x > 0.1:\n",
    "                decisions.append(decision)                \n",
    "                node = target_node\n",
    "                break\n",
    "                \n",
    "    return decisions     \n",
    " \n",
    "decisions = get_solution_path(edge_to_flow_var, dd)\n",
    "decisions[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- we can then turn this into a \"readable solution\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def get_items_from_path(decisions):\n",
    "    solution_items =  []\n",
    "    for i, dec in enumerate(decisions):\n",
    "        if dec == 1:\n",
    "            solution_items.append(i)\n",
    "            \n",
    "    return solution_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "get_items_from_path(decisions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Of course, we can benefit from the DD reduction!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_exact_dd(dd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_number_of_nodes(dd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "..once again, building and solving the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "m = gp.Model(\"knapsack_dd\")\n",
    "m.ModelSense = GRB.MAXIMIZE\n",
    "\n",
    "edge_to_flow_var = build_network_flow_component(m, dd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gurobi Optimizer version 12.0.0 build v12.0.0rc1 (win64 - Windows 10.0 (19045.2))\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i7-10750H CPU @ 2.60GHz, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 6 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Optimize a model with 1 rows, 100 columns and 100 nonzeros\n",
      "Model fingerprint: 0x8ef00fbf\n",
      "Variable types: 0 continuous, 100 integer (100 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [9e+00, 1e+03]\n",
      "  Objective range  [7e+00, 1e+03]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+03, 1e+03]\n",
      "\n",
      "\n",
      "Presolve removed 1 rows and 100 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 12 available processors)\n",
      "\n",
      "Solution count 2: 9147 8817 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 9.147000000000e+03, best bound 9.147000000000e+03, gap 0.0000%\n",
      "CPU times: total: 31.2 ms\n",
      "Wall time: 16.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "m.optimize()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## An Observation for the 0/1 KP Model\n",
    "\n",
    "- let us re-examine the size of the DD before and after the reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nodes before reduction 80725\n",
      "nodes after reduction 19957\n"
     ]
    }
   ],
   "source": [
    "\n",
    "filename = \"./../problems/knapsack/instances/knapPI_1_100_1000_1\"\n",
    "kp_instance = read_kp_instance(filename)\n",
    "dd = build_exact_dd(dp_kp, kp_instance, 0, 0,-1)\n",
    "print(\"nodes before reduction\", get_number_of_nodes(dd))\n",
    "reduce_exact_dd(dd)\n",
    "print(\"nodes after reduction\", get_number_of_nodes(dd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "**Remember:** when reading the instance, we sorted the items according to value/weight, because this yielded the best result for the greedy heuristic\n",
    "\n",
    "- when creating an exact DD, is this still the best sorting / variable ordering?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- turns out not: it is much better to sort according to weight in descending order since this leads to a **smaller** network!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_indexes = np.argsort(-1* kp_instance.weights)\n",
    "kp_instance = KPInstance(kp_instance.values[sorted_indexes], kp_instance.weights[sorted_indexes], kp_instance.capacity, kp_instance.N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nodes before reduction 21618\n",
      "nodes after reduction 12218\n"
     ]
    }
   ],
   "source": [
    "dd = build_exact_dd(dp_kp, kp_instance, 0, 0,-1)\n",
    "print(\"nodes before reduction\", get_number_of_nodes(dd))\n",
    "reduce_exact_dd(dd)\n",
    "print(\"nodes after reduction\", get_number_of_nodes(dd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Is this any better than a standard MIP model?\n",
    "\n",
    "The standard MIP formulation for the 0/1 KP looks as follows:\n",
    "- let $I$ be the set of items, and $W$ be the capacity\n",
    "\n",
    "\n",
    "$$\\min \\sum_{i \\in I}p_i x_i$$\n",
    "\n",
    "s.t.\n",
    "$$\n",
    " \\sum_{i \\in I} x_i \\leq W \\\\\n",
    " x_i \\in \\{0, 1\\} \\quad \\forall i \\in I $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##  In Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gurobi.Constr *Awaiting Model Update*>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = gp.Model(\"knapsack\")\n",
    "\n",
    "m.ModelSense = GRB.MAXIMIZE\n",
    "\n",
    "x = [m.addVar(vtype=GRB.BINARY) for i in range(kp_instance.N)]\n",
    "\n",
    "\n",
    "m.setObjective(gp.quicksum(kp_instance.values[i] * x[i] for i in range(kp_instance.N)))\n",
    "\n",
    "m.addConstr(gp.quicksum(kp_instance.weights[i] * x[i] for i in range(kp_instance.N)) <= kp_instance.capacity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gurobi Optimizer version 12.0.0 build v12.0.0rc1 (win64 - Windows 10.0 (19045.2))\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i7-10750H CPU @ 2.60GHz, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 6 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Optimize a model with 1 rows, 100 columns and 100 nonzeros\n",
      "Model fingerprint: 0x8ef00fbf\n",
      "Variable types: 0 continuous, 100 integer (100 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [9e+00, 1e+03]\n",
      "  Objective range  [7e+00, 1e+03]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+03, 1e+03]\n",
      "\n",
      "\n",
      "Presolve removed 1 rows and 100 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 12 available processors)\n",
      "\n",
      "Solution count 2: 9147 8817 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 9.147000000000e+03, best bound 9.147000000000e+03, gap 0.0000%\n",
      "9147.0\n",
      "selected items: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 13]\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 6.53 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "m.optimize()\n",
    "print(m.objVal)\n",
    "selected = [i for i in range(kp_instance.N) if x[i].x >= 0.99]\n",
    "print(\"selected items: {}\".format(selected))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    ".. this was not a big success for DD, acutually... let's see what comes next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Multiple Knapsack Problem\n",
    "\n",
    "- the multiple knapsack problem is an extension of the 0/1 KP where we do not have a single, but multiple knapsacks\n",
    "- in general, the knapsacks can have different capacities\n",
    "- **but here**, for the sake of simplicity, we assume that all knapsacks have the same capacity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "..let us first define an instance type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "class  MKPInstance(NamedTuple):\n",
    "    values:np.array\n",
    "    weights:np.array\n",
    "    capacity:int\n",
    "    number_of_knapsacks:int\n",
    "    N:int\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "..and an instance creation function that uses the KP instance format to create an MKP instance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "       \n",
    "def create_mkp_instance_from_kp(kp_instance, number_of_knapsacks, weight_factor = 0.5):\n",
    "    \n",
    "    cap = int(weight_factor *np.sum(kp_instance.weights) / number_of_knapsacks)    \n",
    "        \n",
    "    return MKPInstance(kp_instance.values, kp_instance.weights, cap, number_of_knapsacks, kp_instance.N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkp_instance = create_mkp_instance_from_kp(kp_instance, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Multiple Knapsack Problem: Standard MIP formulation\n",
    "\n",
    "\n",
    "- let $I$ be the set of items, let $J$ be the set of knapsacks and $W$ be the capacity\n",
    "- once again, we assume here (as opposed to standard MKP) that $W$ is the same for all $j \\in J$\n",
    "\n",
    "\n",
    "$$\\min \\sum_{i \\in I}\\sum_{j \\in j}  p_i x_{ij} $$\n",
    "\n",
    "s.t.\n",
    "$$\n",
    " \\sum_{i \\in I} x_{ij} \\leq W  \\quad \\forall j \\in J \\\\\n",
    "  \\sum_{j \\in J} x_{ij} \\leq 1  \\quad \\forall i \\in I \\\\\n",
    " x_{ij} \\in \\{0, 1\\} \\quad \\forall i \\in I, j \\in J $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Multiple Knapsack Problem: Solving the standard MIP formulation in Python\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = gp.Model(\"multiple_knapsack\")\n",
    "\n",
    "\n",
    "x = [[m.addVar(vtype=GRB.BINARY) for k in range(mkp_instance.number_of_knapsacks)] for i in range(mkp_instance.N)]\n",
    "\n",
    "\n",
    "m.ModelSense = GRB.MAXIMIZE\n",
    "\n",
    "m.setObjective (gp.quicksum(mkp_instance.values[i] * x[i][k] for i in range(mkp_instance.N)  for k in range(mkp_instance.number_of_knapsacks) ))\n",
    "\n",
    "for k in range(mkp_instance.number_of_knapsacks):\n",
    "    \n",
    "    m.addConstr(gp.quicksum(mkp_instance.weights[i] * x[i][k] for i in range(mkp_instance.N)) <= mkp_instance.capacity)\n",
    "    \n",
    "for i in range(mkp_instance.N):\n",
    "        m.addConstr(gp.quicksum(x[i][k] for k in range(mkp_instance.number_of_knapsacks)) <= 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "..solving it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "m.params.TimeLimit = 2*60 #just to make sure, we'r in class!\n",
    "\n",
    "m.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective 40277.0 upper bound 40390.0 gap %  0.281\n"
     ]
    }
   ],
   "source": [
    "print(\"objective\", m.ObjVal, \"upper bound\", m.ObjBound, f\"gap %  {100*(m.ObjBound - m.ObjVal) / m.ObjVal:0.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## A DP Model for the MKP?\n",
    "\n",
    "How would a DP model look like for the MKP?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "You can use this 0/1 KP model as starting point:\n",
    "\n",
    "- state $x_k$: accumulated weight after adding the first $k-1$ items, $x_0 = 0$\n",
    "- decision $u_k \\in \\{0, 1\\}$ (0: do not add item $k$ to the knapsack; 1: add item $k$)\n",
    "- $U_k(x_k) = \\begin{cases} \n",
    "                \\{0,1\\} \\quad \\mathrm{if} \\quad x_k + w_k \\leq W \\\\\n",
    "                \\{0 \\} \\quad \\mathrm{else}\n",
    "\\end{cases}$\n",
    "\n",
    "- $f(x_k, u_k) = x_k + w_k u_k $\n",
    "\n",
    "- $g(x_k, u_k) = p_k u_k$\n",
    "\n",
    "We have a maximization-objective:\n",
    "\n",
    "$$\\max_{u_0,..,u_k,..u_{N-1}} \\sum_{k=0}^{N-1} g_k(x_k,u_k)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## DP Model for the MKP: In Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def feasible_decisions_mkp(instance, k, acc_weight):    \n",
    "    #if acc_weight + instance.weights[k] <= instance.capacity: return np.array([0,1])\n",
    "    #else: return np.array([0])\n",
    "    return\n",
    "\n",
    "@njit\n",
    "def transition_function_mkp(instance, k, acc_weight, put):\n",
    "    #return acc_weight + put*instance.weights[k]\n",
    "    return\n",
    "\n",
    "@njit\n",
    "def cost_function_mkp(instance, k, acc_weight, put):\n",
    "      #return put*instance.values[k]\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp_mkp = DP(feasible_decisions_mkp, transition_function_mkp,  cost_function_mkp, \"max\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 20\n",
    "kp_instance_small = KPInstance(kp_instance.values[:N], kp_instance.weights[:N],kp_instance.capacity,  N)\n",
    "mkp_instance_small = create_mkp_instance_from_kp(kp_instance_small, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start_state = \n",
    "# sink_state\n",
    "#dd = build_exact_dd(dp_mkp, mkp_instance_small, 0, start_state, sink_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Key idea: Multiple flow units through a single-knapsack DD\n",
    "\n",
    "\n",
    "**Observe the following:**\n",
    "- in the MKP that we consider here (identical capacities), the set of feasible solutions for each knapsack with capacity $W$ is identical to the set of solutions of a single 0/1-KP with capactiy $W$\n",
    "- each item can only be assigned to a **single knapsack**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Now let us dicuss a **key idea** useful in many cases, not only for 0/1 KP:\n",
    "- if we are looking for a solution that can be represented as a set of multiple paths within the same network\n",
    "  - **we can model this as a (multi-unit) flow through a single network**\n",
    "  - that can be modeled as part of a MIP model#\n",
    "  - which gives us the opportunity to add **additional constraints** not represented in the network\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- after solving such a model, we can obtain feasible solutions via **flow decomposition**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Formulating the MKP using a DD-based flow component\n",
    "\n",
    "- let $I$ be the set of items, let $J$ be the set of knapsacks and $W$ be the capacity\n",
    "-  we assume here (as opposed to standard MKP) that $W$ is the same for all $j \\in J$\n",
    "\n",
    "- assume that we have a graph $G=(V,E)$ that is the graph underlying a DD, augmented with a flow circulation arc $e^\\mathrm{circ}$\n",
    "\n",
    "- let $E^i$ be the set of items representing the set edges picking item $i$\n",
    "\n",
    "Then, we can formulate the MKP as follows:\n",
    "\n",
    "$$\\min \\sum_{e \\in E} c_e x_e$$\n",
    "\n",
    "s.t.\n",
    "$$\n",
    " \\sum_{e \\in v^-} x_e = \\sum_{e \\in v^+} x_e \\quad \\forall v \\in N \\\\\n",
    " x_e^\\mathrm{circ} = |J| \\\\ \n",
    " \\sum_{e \\in E^i} x_e \\leq 1 \\quad \\forall i \\in I \\\\ \n",
    " x_e \\in \\{0, 1\\} \\quad \\forall e \\in E $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "..what is \"surprising\" / different to the standard MKP formulation here?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Formulating the MKP using a DD-based flow component: In Python\n",
    "..building reduced DD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nodes before reduction 33696\n",
      "nodes after reduction 20262\n"
     ]
    }
   ],
   "source": [
    "dd = build_exact_dd(dp_kp, mkp_instance, 0, 0,-1)\n",
    "print (\"nodes before reduction\", get_number_of_nodes(dd))\n",
    "reduce_exact_dd(dd)\n",
    "print (\"nodes after reduction\", get_number_of_nodes(dd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "..creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = gp.Model(\"mk_knapsack_dd\")\n",
    "\n",
    "m.ModelSense = GRB.MAXIMIZE\n",
    "\n",
    "# network flow component\n",
    "edge_to_flow_var = build_network_flow_component(m, dd, mkp_instance.number_of_knapsacks)\n",
    "\n",
    "# create the sets of edges per item\n",
    "item_variables = [[] for i in range(mkp_instance.N)]\n",
    "for e, var in edge_to_flow_var.items():    \n",
    "    if e[2]==1:\n",
    "        item_variables[e[0][0]].append(var)        \n",
    "\n",
    "# create the constraints forcing every item to be picked at most onces     \n",
    "for i, item_vars in enumerate(item_variables): \n",
    "    m.addConstr(gp.quicksum(item_var for item_var in item_vars)  <= 1 )                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "..solving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter TimeLimit to value 120\n",
      "Gurobi Optimizer version 12.0.0 build v12.0.0rc1 (win64 - Windows 10.0 (19045.2))\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i7-10750H CPU @ 2.60GHz, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 6 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Non-default parameters:\n",
      "TimeLimit  120\n",
      "\n",
      "Optimize a model with 20362 rows, 34325 columns and 82713 nonzeros\n",
      "Model fingerprint: 0x9b34cb44\n",
      "Variable types: 0 continuous, 34325 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [7e+00, 1e+03]\n",
      "  Bounds range     [2e+01, 2e+01]\n",
      "  RHS range        [1e+00, 1e+00]\n",
      "Presolve removed 11926 rows and 11885 columns\n",
      "Presolve time: 0.44s\n",
      "Presolved: 8436 rows, 22440 columns, 59189 nonzeros\n",
      "Variable types: 0 continuous, 22440 integer (14492 binary)\n",
      "Found heuristic solution: objective 29853.000000\n",
      "\n",
      "Root simplex log...\n",
      "\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "   27993    4.0433015e+04   2.992172e+02   0.000000e+00      5s\n",
      "   35032    4.0388284e+04   0.000000e+00   0.000000e+00      8s\n",
      "\n",
      "Root relaxation: objective 4.038828e+04, 35032 iterations, 7.04 seconds (9.89 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 40388.2835    0  234 29853.0000 40388.2835  35.3%     -    7s\n",
      "H    0     0                    39413.000000 40388.2835  2.47%     -    7s\n",
      "H    0     0                    39453.000000 40388.2835  2.37%     -    8s\n",
      "H    0     0                    39563.000000 40388.2835  2.09%     -    8s\n",
      "H    0     0                    40277.000000 40388.2835  0.28%     -    8s\n",
      "H    0     0                    40290.000000 40388.2835  0.24%     -    9s\n",
      "     0     0 40388.1733    0  260 40290.0000 40388.1733  0.24%     -   10s\n",
      "H    0     0                    40377.000000 40388.1034  0.03%     -   12s\n",
      "     0     0 40388.1034    0  272 40377.0000 40388.1034  0.03%     -   12s\n",
      "     0     0 40388.1034    0  302 40377.0000 40388.1034  0.03%     -   13s\n",
      "     0     0 40388.1034    0  189 40377.0000 40388.1034  0.03%     -   20s\n",
      "     0     0 40388.1018    0  211 40377.0000 40388.1018  0.03%     -   21s\n",
      "     0     0     cutoff    0      40377.0000 40377.0000  0.00%     -   22s\n",
      "\n",
      "Cutting planes:\n",
      "  Gomory: 1\n",
      "  MIR: 2\n",
      "  StrongCG: 1\n",
      "  Zero half: 5\n",
      "\n",
      "Explored 1 nodes (61972 simplex iterations) in 22.03 seconds (25.49 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 7: 40377 40290 40277 ... 29853\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 4.037700000000e+04, best bound 4.037700000000e+04, gap 0.0000%\n",
      "objective 40377.0 upper bound 40377.0 gap %  0.000\n",
      "CPU times: total: 50.1 s\n",
      "Wall time: 22.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "m.params.TimeLimit = 2*60\n",
    "m.optimize()\n",
    "\n",
    "print(\"objective\", m.ObjVal, \"upper bound\", m.ObjBound, f\"gap %  {100*(m.ObjBound - m.ObjVal) / m.ObjVal:0.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Obtaining Paths via Flow Decomposition\n",
    ".. now let us see how to obtain the solution for each of the knapsacks:\n",
    "- the core idea here is to \"walk through the DD\" from source to sink $|J|$ times\n",
    "- we start by initiating a dict stores the remaining flow through each edge\n",
    "  - initialized by the flow solution\n",
    "- then we extract one path by following a \"non-zero\" path from source to sink, reducing the remaining flow on each visited edge\n",
    "- until there is no more flow\n",
    "\n",
    "**Observe:**\n",
    "\n",
    "In general, such a flow decomposition is not unique!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decompose_flow_to_solution_paths(edge_to_flow_var, dd):\n",
    "    \n",
    "    paths = []\n",
    "    \n",
    "    ## inoit    \n",
    "    edge_to_remaining_flow = {}    \n",
    "    for e, flow_var in edge_to_flow_var.items():\n",
    "        edge_to_remaining_flow[e]  = round(flow_var.x)        \n",
    "    \n",
    "    circ_edge = ((dd.number_of_layers - 1, dd.sink_state), (0,dd.source_state), -1)   \n",
    "    \n",
    "    while edge_to_remaining_flow[circ_edge] > 0:\n",
    "\n",
    "        edge_to_remaining_flow[circ_edge] -= 1\n",
    "        \n",
    "        decisions = []\n",
    "        node = (0, dd.source_state)\n",
    "\n",
    "        while node[1] != dd.sink_state:\n",
    "            for node, target_node, decision in dd.g.out_edges(node, keys=True):\n",
    "                if edge_to_remaining_flow[(node, target_node, decision)]  > 0:\n",
    "                    decisions.append(decision)\n",
    "                    edge_to_remaining_flow[(node, target_node, decision)] -= 1  \n",
    "                    \n",
    "                    node = target_node \n",
    "                    break\n",
    "                    \n",
    "        paths.append(decisions)\n",
    "                \n",
    "    return paths\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Obtaining Paths via Flow Decomposition: Trying it out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[43, 57, 73],\n",
       " [41, 46, 90, 99],\n",
       " [40, 59, 74],\n",
       " [39, 44, 96],\n",
       " [38, 58, 79],\n",
       " [37, 61, 70],\n",
       " [35, 64, 72],\n",
       " [34, 53, 91],\n",
       " [30, 48],\n",
       " [28, 65, 84, 89],\n",
       " [27, 66, 83, 92],\n",
       " [19, 63, 93],\n",
       " [17, 60, 97],\n",
       " [15, 67, 88],\n",
       " [14, 62, 95],\n",
       " [11, 78, 82],\n",
       " [9, 75, 86],\n",
       " [3, 85, 87, 98],\n",
       " [2, 77, 94],\n",
       " [0, 71]]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths = decompose_flow_to_solution_paths(edge_to_flow_var, dd)\n",
    "\n",
    "def get_items_from_path(decisions):\n",
    "    solution_items =  []\n",
    "    for i, dec in enumerate(decisions):\n",
    "        if dec == 1:\n",
    "            solution_items.append(i)\n",
    "            \n",
    "    return solution_items\n",
    "\n",
    "knapsack_items = [ get_items_from_path(path) for path in paths]\n",
    "knapsack_items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Concluding Remarks\n",
    "\n",
    "- we created our first DD-based MIPs \n",
    "- these MIPs are often large (although the DD reduction generally helps)\n",
    "- but a key advantage is that they can model the flow corresponding to multiple identical objects (e.g. knapsacks, workers with identical skills) in a single network which typically reduces symmetry\n",
    "- and: these models usually have a stronger LP relaxation than \"standard formulations\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- these DD-based MIPs can be viewed as a special case of state-expanded networks that we will consider next week"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [conda env:DPModels2024]",
   "language": "python",
   "name": "conda-env-DPModels2024-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
